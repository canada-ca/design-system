---
altLangPage: https://conception.canada.ca/sondage/epurer-taches.html
breadcrumbs:
 - title: About Canada.ca
   link: https://www.canada.ca/en/government/about.html
 - title: Analytics and feedback
   link: https://www.canada.ca/en/analytics.html
 - title: GC Task Success Survey
   link: survey.html
dateModified: 2023-03-28
description: ""
title: Task list clean up
---

<div class="gc-stp-stp">
    <div class="row">
        <ul class="toc lst-spcd col-md-12">
            <li class="col-md-4 col-sm-6"><a class="list-group-item" href="writing-tasks.html">Choosing and writing tasks</a></li>
            <li class="col-md-4 col-sm-6"><a class="list-group-item" href="updating-tasks.html">Add or edit tasks</a></li>
            <li class="col-md-4 col-sm-6"><a class="list-group-item" href="custom-list.html">Request a custom task list</a></li>
            <li class="col-md-4 col-sm-6"><a class="list-group-item active">Task list clean up</a></li>
        </ul>
    </div>
</div>
    
Reviewing tasks in the survey helps ensure top tasks make up the majority of tasks in the survey and that tasks are unambiguous and clearly worded.

## On this page

* [Top tasks are the majority of tasks in the survey](#top-tasks-are-the-majority-of-tasks-in-the-survey)
* [Tasks in the survey are clear to users](#tasks-in-the-survey-are-clear-to-users)
* [Steps for cleaning up task lists](#steps-for-cleaning-up-task-lists)

## Top tasks are the majority of tasks in the survey

Remove tasks that are not true top tasks (often these will have insufficient response rates after a year of data collection).

Non top tasks add clutter to the survey and make it harder for users to find and select the task they are looking for.

Aim for 80% of your tasks to achieve a sufficient response rate over the course of a fiscal year.

Doing this means that you have confidence in the data and can use it for reporting and prioritization activities.

A large number of tasks with insufficient data detracts from the survey's reputation as a reliable measurement and research tool.

## Tasks in the survey are clear to users

Fine tuning the wording of tasks helps ensure survey respondents choose the correct task resulting in:

* reduced confusion between tasks with similar wording
* fewer responses diverted into the Other category
* improved confidence in the success score

This can also help when the task is understood when taken out of survey context (for example, when presented online as open data or referred to in communications materials).

## Steps for cleaning up task lists

<details>
    <summary><span id="step1" class="h3">Step 1: Identify your low response tasks</span></summary>
    <p>Tasks that have not received 100 responses per year may be good candidates to be removed, merged into another task, or have the task label improved.</p>
    <p>You may notice that departmental priorities are not always aligned with what people are coming to the site to do.</p>
    <p>You may need to identify other ways to measure departmental priorities that are not (yet) top tasks to users.</p>
    <h4>How to do it</h4>
    <ol>
        <li>Look up your response rates</li>
        <li>Identify tasks with fewer than 100 responses</li>    
    </ol>
    <h4>Outcomes for this step</h4>
    <ol>
        <li>Have a list of low response tasks</li>
        <li>Have a tentative list of tasks for removal OR decide if you need to gather additional responses to have sufficient data
            <ul>
                <li>Example: If you have a seasonal/time specific task - you may want to consider increasing the invitation rate during certain periods.</li>
            </ul>
        </li>
    </ol>
</details>

<details>
    <summary><span id="step2" class="h3">Step 2: Identify where ‘Other’ ranks in your task list</span></summary>
    <p>Find out if “Other” is one of the top 3 tasks within your task list.</p>
    <p>If it is, this is a good indicator that:</p>
    <ul>
        <li>there are tasks currently missing from your task list and/or</li>
        <li>people are selecting ‘other’ when task wording is not clear</li>
    </ul>
    <h4>How to do it</h4>
    <p>Use Adobe Analytics or the latest cumulative TSS report to identify where ‘Other’ ranks in your task list.</p>
    <h4>Outcomes for this step</h4>
    <p>Understand if your task list is working for users with the right top tasks - where ‘Other’ is not one of your top 3 tasks.</p>
    <p>Using the information you’ve gathered in Step 1 and Step 2, you will now know:</p>
    <ul>
        <li>Low response tasks (potential tasks to remove from your task list)</li>
        <li>Whether responses to ‘Other’ are diverting responses away from tasks in your list</li>
    </ul>
</details>

<details>
    <summary><span id="step3" class="h3">Step 3: Review ‘Other” comments</span></summary>
    <p>Reading comments entered as “Other - Reason for my visit is not in this list” can help you understand:</p>
    <ul>
        <li>what tasks may be missing from your task list</li>
        <li>why people are selecting ‘other’ (like unclear task wording)</li>
    </ul>
    <h4>How to do it</h4>
    <ul>
        <li>Download task comments from the Feedback Viewer.</li>
        <li>Filter your comments to isolate comments entered as other </li>
        <li>Categorize other comments into tasks or topics.<br>
            A word cloud generator can also help you identify the keywords in your “other” comments to give you a quick idea of what types of tasks people are entering.</li>
    </ul>
    <h4>Outcomes for this step</h4>
    <ol>
        <li>Identify if there are top task gaps in your task list and draft new tasks to add to the survey </li>
        <li>Identify if existing tasks in your list need clearer wording</li>
        <li>Gather evidence to merge or remove low response tasks from your the survey</li>
    </ol>
</details>

<details>
    <summary><span id="step4" class="h3">Step 4: Validate comments received for survey tasks</span></summary>
    <p>Check that comments align with the selected task. If the comments don't align with the task, this is a good indicator that the task is not clear to users.</p>
    <h4>How to do it</h4>
    <p>Use the survey comments that you downloaded in Step 3 from the Feedback Viewer.</p>
    <p>Smaller departments may be able to review all comments entered for their tasks, but larger departments with a high volume of comments may opt to work with a smaller sample.</p>
    <h4>Outcomes for this step</h4>
    <ol>
        <li>Identify if users are selecting the wrong task - this can occur when there are similarly worded tasks. </li>
        <li>Revise problematic task labels</li>
    </ol>
</details>

<details>
    <summary><span id="step5" class="h3">Step 5: Revise your task list based on previous steps</span></summary>
    <p>Tasks work best when they are specific, do not overlap with other tasks, and use plain language. Use your findings from the previous steps to revise your task lists.</p>
    <p><a href="writing-tasks.html">Guidance on choosing and writing tasks</a></p>
    <h4>Outcomes for this step</h4>
    <p>A finalized list of updated tasks that are ready to be translated and then submitted to Principal Publisher.</p>
</details>

<details>
    <summary><span id="step6" class="h3">Step 6: Submit revisions </span></summary>
    <p>Institutions can request edits to the task list from the Principal Publisher.</p>
    <p>Updates to the task list are compiled and implemented on a monthly basis.</p>
    <p><a href="updating-tasks.html">How to request changes</a></p>
</details>
